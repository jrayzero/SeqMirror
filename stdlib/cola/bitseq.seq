#from C import cola_bitstr_uint(u64, int) -> str

# TODO really need to double check that my integer sizes/bit ops are correct cause I'm not great with this part
u1 = UInt[1]

# Note to self: I can't just use UInt[N] here because I don't statically know the size in every case

# basic idea: the individual values you append (or init with) have their MSB bits trimmed off to match the specified size
# then that value is shifted toward the MSB of the current bitseq. So, bits are always packed from MSB->LSB.
# bit_seqs[0] -> MSB 
# bit_seqs[-1] -> LSB
# Thus, bitwidths for appending measure from LSB to MSB, but effective width measures from MSB->LSB
# TODO I coudl parameterize this by the size of each bitseq that I want (If it allows me to do defaults, I can have BitSeq[N=64] or somehting)
class BitSeq:

  # for storage, everythign is aligned towards the LSB. But when you pack, we align to the MSB, pack after the MSB (towards
  # the LSB), and then realign to the LSB
  effective_width: int
  bit_seqs: list[u64]
  nseqs: int

  # completely brain-dead and slow bit packing that just iterates through to pack one bit at a time
  def _pack_bits(self, val: u64, width: int):
    it = iter(val)
    # skip the MSBs we don't need
    for _ in range(64-width):      
      next(it)
    for i in range(width):
      v = u64(next(it))
      cur_bit_seq = u64(0)
      if self.nseqs == 0 or self.effective_width & 63 == 0:
        # need a new sequence
        self.bit_seqs.append(cur_bit_seq)
        self.nseqs += 1
      else:
        # MSB align the current bitseq (since it is always stored as LSB aligned)
        align_shift = 64 - (self.effective_width & 63)
        # sanity check
        assert align_shift != 64 # should never reach this
        cur_bit_seq = self.bit_seqs[-1] << u64(align_shift)
      msb_bit_idx = self.effective_width & 63 # counted from the MSB->LSB
      # move the single bit to the correct lcation
      v <<= u64(63-msb_bit_idx) 
      cur_bit_seq |= v
      # LSB align again
      self.effective_width += 1
      rshift = 63-msb_bit_idx
      self.bit_seqs[-1] = (cur_bit_seq >> u64(rshift))

  # width here is measured from the LSB->MSB, which is different than the effective_width which measures
  # from MSB->LSB. I do this because if you want to pass in decimal values (say 10, which is 0b1010, or maybe 0b000001010),
  # you wouldn't want to take the MSB bits in this case.

  def __init__(self):
    self.effective_width = 0
    self.bit_seqs = []
    self.nseqs = 0

  # width can be different than the actual type since you might not want all of the bits
  def __init__(self, val: u1):
    self.__init__()
    self._pack_bits(u64(val), 1)

  def __init__(self, val: u8, width: int=8):
    self.__init__()
    assert width >= 1 and width <= 8
    self._pack_bits(u64(val), width)

  def __init__(self, val: u16, width: int=16):
    self.__init__()
    assert width >= 1 and width <= 16
    self._pack_bits(u64(val), width)

  def __init__(self, val: u32, width: int=32):
    self.__init__()
    assert width >= 1 and width <= 32
    self._pack_bits(u64(val), width)

  def __init__(self, val: u64, width: int=64):
    self.__init__()
    assert width >= 1 and width <= 64
    self._pack_bits(u64(val), width)

  def __init__(self, val: int, width: int=64): 
    self.__init__()
    assert width >= 1 and width <= 64
    self._pack_bits(u64(val), width)

  def __init__(self, s: str, width: int):
    self.__init__()
    assert width >= 1 and width <= 64
    assert 8 * len(s) >= width # need enough bits
    sum = u64(0)   
    # go through each bit. This is so we can handle odd numbers of bits
    for idx in range(width):
      cur_byte = idx // 8
      # get the bit we are intersted in
      bitidx = idx & 7
      bit = u1(u8(s.ptr[cur_byte]) >> u8(bitidx))
      bit &= u1(1)
      shft = u64(cur_byte * 8 + (idx & 7))
      shftbit = u64(bit) << shft
      sum |= shftbit
    self._pack_bits(sum, width)

  def nbits(self) -> int:
    return self.effective_width

  def pack(self, val: BitSeq):
    w = val.effective_width
    for bitseq in val.bit_seqs[:-1]:
      self._pack_bits(bitseq, 64)
      w -= 64
    # need to align the last one to the right hand side
    last_seq = val.bit_seqs[-1]
    self._pack_bits(last_seq, w)

  def pack(self, val: u1):
    self._pack_bits(u64(val), 1)

  def pack(self, val: u8, width: int=8):
    assert width >= 1 and width <= 8
    self._pack_bits(u64(val), width)

  def pack(self, val: u16, width: int=16):
    assert width >= 1 and width <= 16
    self._pack_bits(u64(val), width)

  def pack(self, val: u32, width: int=32):
    assert width >= 1 and width <= 32
    self._pack_bits(u64(val), width)

  def pack(self, val: u64, width: int=64):
    assert width >= 1 and width <= 64
    self._pack_bits(u64(val), width)

  def pack(self, val: int, width: int=64): 
    assert width >= 1 and width <= 64
    self._pack_bits(u64(val), width)

  def __iter__(self) -> Generator[UInt[1]]:
    w = self.effective_width
    for i in range(self.nseqs-1):      
      for b in self.bit_seqs[i]:
        yield UInt[1](b)
        w -= 1
    # get remaining bits
    it = self.bit_seqs[-1].msb_iter_from(64-w)
    for i in range(w):
      yield next(it)
    it.destroy()

  # prints out in binary
  def __str__(self) -> str:
    s = ''
    for b in self:
      s += str(b)
    return '0b' + s

  def __eq__(self, other: BitSeq) -> bool:
    if self.effective_width != other.effective_width:
      return False
    w = self.effective_width
    for i in range(self.nseqs-1):
      self_bs = self.bit_seqs[i]
      other_bs = other.bit_seqs[i]
      if self_bs != other_bs:
        return False
      w -= 64
    # check remaining bits
    self_bs = self.bit_seqs[self.nseqs-1]
    other_bs = other.bit_seqs[self.nseqs-1]
    if self_bs != other_bs:
      return False
    return True

  def __eq__[N: int](self, other: UInt[N]):
    bother = BitSeq(other, N)
    return self == bother
      
  def __ne__(self, other):
    return not (self == other)

  def _iter_ones(self):
    idx = 0 
    w = self.effective_width
    for i in range(self.nseqs-1):
      bs = self.bit_seqs[i]
      for b in range(64):
        bit = (bs >> u64(64-b-1)) & u64(1)
        if bit == u64(1):
          yield idx
        idx += 1
        w -= 1
    bs = self.bit_seqs[-1]
    for b in range(w):
      # remember, stored as LSB aligned
      bit = u1((bs >> u64(w - b - 1)) & u64(1))
      if bit == u1(1):
        yield idx
      idx += 1    

  def __ge__(self, other: BitSeq):
    # go through from MSB to LSB comparing the values
    self_iter = self._iter_ones()
    other_iter = other._iter_ones()
    while True:
      try:
        sb = next(self_iter)
        ob = next(other_iter)
        if sb == ob:
          continue
        else:
          self_iter.destroy()
          other_iter.destroy()
          # found a differing index
          return sb <= ob # <= b/c it's from the MSB side
      except StopIteration:
        self_iter.destroy()
        other_iter.destroy()
        # no more ones, so they both had the same till this point
        return True

  def __gt__(self, other: BitSeq):
    # go through from MSB to LSB comparing the values
    self_iter = self._iter_ones()
    other_iter = other._iter_ones()
    while True:
      try:
        sb = next(self_iter)
        ob = next(other_iter)
        if sb == ob:
          continue
        else:
          # found a differing index
          self_iter.destroy()
          other_iter.destroy()
          return sb < ob
      except StopIteration:
        self_iter.destroy()
        other_iter.destroy()
        # no more ones, so they both had the same till this point
        return False

  def __le__(self, other: BitSeq):
    return not (self > other)

  def __lt__(self, other: BitSeq):
    return not (self >= other)

  def __int__(self) -> int:
    if self.nseqs == 0:
      return 0
    else:
      return int(self.bit_seqs[0])

# used in conjunction with int/uint[N].new to get stuff as raw unisnged chars
# get raw unsigned characters from a string
@extend
class byte:
  def zext_or_trunc[T: int](self) -> UInt[T]:
    if 8 < T:
      return UInt.uint_zext[8,T](self)
    elif 8 == T:
      return UInt.ident[8](self)
    else: # N > T
      return UInt.uint_trunc[8,T](self)    

@extend 
class UInt[N]:

  def __new__(val: BitSeq) -> UInt[N]:
    ui = UInt[N]()
    idx = 0
    n = N-1
    for b in val:
      ui |= (UInt[N](b) << UInt[N](n))
      n -= 1    
    return ui

  def __new__(val) -> UInt[N]:
    return val.zext_or_trunc[N]()
  @llvm
  def ident[T: int](what) -> UInt[T]:
    ret i{=T} %what
  @llvm
  def uint_zext[F: int, T: int](what) -> UInt[T]:
    %0 = zext i{=F} %what to i{=T}
    ret i{=T} %0
  @llvm
  def uint_trunc[F: int, T: int](what) -> UInt[T]:
    %0 = trunc i{=F} %what to i{=T}
    ret i{=T} %0
  def zext_or_trunc[T: int](self) -> UInt[T]:
    if N < T:
      return UInt.uint_zext[N,T](self)
    elif N == T:
      return self
    else: # N > T
      return UInt.uint_trunc[N,T](self)

  # this is MSB to LSB iter
  def __iter__(self) -> Generator[u1]:
    return self.msb_iter_from(0)

  # starts at idx relative to msb
  def msb_iter_from(self, idx):
    for i in range(N-idx):
      yield u1(self >> UInt[N]((N-idx-i-1)))

  def __eq__(self, other: BitSeq):
    return BitSeq(self, N) == other

  def __neq__(self, other: BitSeq):
    return BitSeq(self, N) != other

  def __ge__(self, other: BitSeq):
    return BitSeq(self, N) >= other

  def __gt__(self, other: BitSeq):
    return BitSeq(self, N) > other

  def __le__(self, other: BitSeq):
    return BitSeq(self, N) <= other

  def __lt__(self, other: BitSeq):
    return BitSeq(self, N) < other

@extend
class File:
  def write(self, arr: Array[byte]):
    self._ensure_open() 
    _C.fwrite(arr.ptr, 1, len(arr), self.fp) 
    self._ensure_open() 

@extend
class str:
  def __sub__(self, other: str) -> u8:
    return u8(BitSeq(self, 8)) - u8(BitSeq(other, 8))
